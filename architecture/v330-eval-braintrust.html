<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>V3.3.0 Prompt Evaluation &amp; Braintrust Setup | Ali MVP</title>
  <style>
    @font-face { font-family: 'Metro Sans'; src: url('../fonts/metrosans-regular-webfont.woff2') format('woff2'); font-weight: 400; font-display: swap; }
    @font-face { font-family: 'Metro Sans'; src: url('../fonts/metrosans-medium-webfont.woff2') format('woff2'); font-weight: 500; font-display: swap; }
    @font-face { font-family: 'Metro Sans'; src: url('../fonts/metrosans-semi-bold-webfont.woff2') format('woff2'); font-weight: 600; font-display: swap; }
    @font-face { font-family: 'Metro Sans'; src: url('../fonts/metrosans-bold-webfont.woff2') format('woff2'); font-weight: 700; font-display: swap; }
    @font-face { font-family: 'Moret'; src: url('../fonts/Moret-Regular.otf') format('opentype'); font-weight: 400; font-display: swap; }
    @font-face { font-family: 'Moret'; src: url('../fonts/Moret-RegularOblique.otf') format('opentype'); font-weight: 400; font-style: italic; font-display: swap; }

    :root {
      --ali-bg-page: #F2F2F2;
      --ali-bg-card: #FFFFFF;
      --ali-text-black: #000000;
      --ali-text-grey: #555555;
      --ali-text-body: #404040;
      --ali-border-sharp: #000000;
      --ali-accent: #8A41E6;
      --ali-accent-light: #F3EAFF;
      --ali-success: #22C55E;
      --ali-warning: #F59E0B;
      --ali-danger: #EF4444;
      --ali-font-serif: 'Moret', Georgia, serif;
      --ali-font-sans: 'Metro Sans', -apple-system, BlinkMacSystemFont, 'Segoe UI', sans-serif;
    }

    * { margin: 0; padding: 0; box-sizing: border-box; }
    body { font-family: var(--ali-font-sans); background: var(--ali-bg-page); color: var(--ali-text-body); line-height: 1.6; -webkit-font-smoothing: antialiased; }
    .container { max-width: 1000px; margin: 0 auto; padding: 40px 24px; }

    .masthead { display: flex; justify-content: center; gap: 16px; padding: 16px 0; margin-bottom: 32px; flex-wrap: wrap; }
    .masthead-badge { font-size: 10px; font-weight: 600; letter-spacing: 0.12em; text-transform: uppercase; color: var(--ali-text-black); padding: 8px 16px; background: var(--ali-bg-card); border: 1px solid var(--ali-border-sharp); border-radius: 4px; }
    .masthead-badge.updated { border-color: var(--ali-accent); color: var(--ali-accent); }

    .hero { text-align: center; padding: 32px 24px 56px; max-width: 720px; margin: 0 auto; }
    .hero h1 { font-family: var(--ali-font-serif); font-style: italic; font-size: 44px; font-weight: 400; color: var(--ali-text-black); margin-bottom: 16px; line-height: 1.1; }
    .hero .subtitle { font-size: 18px; color: var(--ali-text-grey); margin-bottom: 24px; }
    .hero .meta { display: flex; justify-content: center; gap: 24px; font-size: 12px; color: var(--ali-text-grey); text-transform: uppercase; letter-spacing: 0.1em; }

    section { margin-bottom: 48px; }
    .section-header { text-align: center; margin-bottom: 32px; }
    .section-label { font-size: 10px; font-weight: 700; letter-spacing: 0.15em; text-transform: uppercase; color: var(--ali-accent); margin-bottom: 8px; }
    .section-title { font-family: var(--ali-font-serif); font-style: italic; font-size: 32px; font-weight: 400; color: var(--ali-text-black); }

    .card { background: var(--ali-bg-card); border-radius: 12px; padding: 32px; margin-bottom: 24px; box-shadow: 0 4px 6px rgba(0,0,0,0.05); border-left: 4px solid var(--ali-accent); }
    .card h3 { font-size: 18px; font-weight: 600; margin-bottom: 12px; color: var(--ali-text-black); }
    .card p { margin-bottom: 12px; }
    .card ul { padding-left: 20px; margin-bottom: 12px; }
    .card li { margin-bottom: 6px; }

    .insight-box { background: linear-gradient(135deg, var(--ali-accent-light), #EDE9FE); border-radius: 12px; padding: 24px 32px; margin-bottom: 24px; border: 1px solid rgba(138,65,230,0.2); }
    .insight-box .label { font-size: 10px; font-weight: 700; letter-spacing: 0.15em; text-transform: uppercase; color: var(--ali-accent); margin-bottom: 8px; }

    /* Score tables */
    table { width: 100%; border-collapse: collapse; margin: 16px 0; font-size: 14px; }
    th { background: var(--ali-text-black); color: white; padding: 12px 16px; text-align: left; font-weight: 600; font-size: 11px; text-transform: uppercase; letter-spacing: 0.08em; }
    td { padding: 10px 16px; border-bottom: 1px solid #E5E7EB; }
    tr:hover td { background: #FAFAFA; }
    .score-win { color: var(--ali-success); font-weight: 700; }
    .score-lose { color: var(--ali-danger); font-weight: 700; }
    .score-tie { color: var(--ali-text-grey); font-weight: 600; }
    .score-big { font-size: 28px; font-weight: 700; }
    .score-label { font-size: 11px; color: var(--ali-text-grey); text-transform: uppercase; letter-spacing: 0.1em; }

    /* Score cards grid */
    .score-grid { display: grid; grid-template-columns: repeat(3, 1fr); gap: 16px; margin: 24px 0; }
    .score-card { background: var(--ali-bg-card); border-radius: 12px; padding: 24px; text-align: center; box-shadow: 0 4px 6px rgba(0,0,0,0.05); }
    .score-card.winner { border: 2px solid var(--ali-accent); }
    .score-card .system-name { font-size: 12px; font-weight: 600; text-transform: uppercase; letter-spacing: 0.1em; margin-bottom: 8px; color: var(--ali-text-grey); }
    .score-card .score-value { font-size: 48px; font-weight: 700; line-height: 1; margin-bottom: 4px; }
    .score-card .score-unit { font-size: 14px; color: var(--ali-text-grey); }
    .score-card .score-trend { font-size: 12px; margin-top: 4px; }

    /* Methodology diagram */
    .method-flow { display: flex; align-items: center; justify-content: center; gap: 12px; margin: 24px 0; flex-wrap: wrap; }
    .method-step { background: var(--ali-bg-card); border: 2px solid var(--ali-accent); border-radius: 8px; padding: 12px 20px; text-align: center; min-width: 140px; }
    .method-step .step-label { font-size: 10px; font-weight: 700; letter-spacing: 0.1em; text-transform: uppercase; color: var(--ali-accent); margin-bottom: 4px; }
    .method-step .step-detail { font-size: 13px; font-weight: 500; }
    .method-arrow { font-size: 24px; color: var(--ali-accent); font-weight: 700; }

    /* Criteria breakdown */
    .criteria-bar { display: flex; align-items: center; padding: 8px 0; border-bottom: 1px solid #F0F0F0; }
    .criteria-bar:last-child { border-bottom: none; }
    .criteria-name { width: 200px; font-size: 13px; font-weight: 500; flex-shrink: 0; }
    .criteria-scores { flex: 1; display: flex; gap: 8px; align-items: center; }
    .bar-container { flex: 1; height: 24px; background: #F0F0F0; border-radius: 4px; position: relative; overflow: hidden; }
    .bar-fill { height: 100%; border-radius: 4px; display: flex; align-items: center; justify-content: flex-end; padding-right: 8px; font-size: 11px; font-weight: 600; color: white; min-width: 30px; }
    .bar-ali { background: var(--ali-accent); }
    .bar-gpt { background: #10B981; }

    /* Steps */
    .step { display: flex; gap: 20px; margin-bottom: 24px; }
    .step-num { width: 36px; height: 36px; background: var(--ali-accent); color: white; border-radius: 50%; display: flex; align-items: center; justify-content: center; font-weight: 700; font-size: 16px; flex-shrink: 0; }
    .step-content { flex: 1; }
    .step-content h4 { font-size: 16px; font-weight: 600; margin-bottom: 4px; }
    .step-content p { font-size: 14px; color: var(--ali-text-grey); }

    /* Action button */
    .action-btn { display: inline-block; background: var(--ali-accent); color: white; padding: 12px 32px; border-radius: 8px; text-decoration: none; font-weight: 600; font-size: 14px; letter-spacing: 0.02em; }
    .action-btn:hover { opacity: 0.9; }

    /* Changelog */
    .change-item { display: flex; gap: 12px; margin-bottom: 16px; }
    .change-tag { font-size: 10px; font-weight: 700; letter-spacing: 0.1em; text-transform: uppercase; padding: 2px 10px; border-radius: 3px; flex-shrink: 0; height: 20px; display: flex; align-items: center; margin-top: 3px; }
    .tag-new { background: #DCFCE7; color: #166534; }
    .tag-changed { background: #FEF3C7; color: #92400E; }
    .tag-fixed { background: #DBEAFE; color: #1E40AF; }
    .tag-removed { background: #FEE2E2; color: #991B1B; }

    /* Full criterion table with all 20 */
    .criterion-full td:nth-child(2), .criterion-full td:nth-child(3), .criterion-full td:nth-child(4), .criterion-full td:nth-child(5) { text-align: center; }
    .criterion-full th:nth-child(2), .criterion-full th:nth-child(3), .criterion-full th:nth-child(4), .criterion-full th:nth-child(5) { text-align: center; }

    /* Responsive */
    @media (max-width: 640px) {
      .hero h1 { font-size: 32px; }
      .score-grid { grid-template-columns: 1fr; }
      .criteria-name { width: 120px; font-size: 11px; }
      .hero .meta { flex-direction: column; gap: 8px; }
      .method-flow { flex-direction: column; }
      .method-arrow { transform: rotate(90deg); }
    }
  </style>
</head>
<body>
  <div class="container">
    <!-- Masthead -->
    <div class="masthead">
      <span class="masthead-badge">Ali MVP</span>
      <span class="masthead-badge">Architecture</span>
      <span class="masthead-badge updated">Updated February 8, 2026</span>
    </div>

    <!-- Hero -->
    <div class="hero">
      <h1>V3.3.0 Prompt Evaluation &amp; Braintrust Testing</h1>
      <p class="subtitle">Ali's conversation engine evaluated against GPT-4o and Gemini across 5 negotiation scenarios, scored on Tom's 20 criteria by an automated LLM judge. Updated with Run 2 results (Feb 8) and expanded scoring methodology.</p>
      <div class="meta">
        <span>Prompt: V3.3.0</span>
        <span>Model: Claude Sonnet</span>
        <span>20 Criteria / 5 Scenarios / 2 Runs</span>
      </div>
    </div>

    <!-- How Scoring Works -->
    <section>
      <div class="section-header">
        <div class="section-label">Methodology</div>
        <div class="section-title">How Scoring Works</div>
      </div>

      <div class="card">
        <h3>The Evaluation Pipeline</h3>
        <p>Each evaluation run sends the <strong>same negotiation scenario</strong> to three different AI systems, then scores every response against Tom's 20 criteria using an automated judge.</p>

        <div class="method-flow">
          <div class="method-step">
            <div class="step-label">Step 1</div>
            <div class="step-detail">5 Scenarios<br><span style="font-size: 11px; color: var(--ali-text-grey);">Same prompt to all 3</span></div>
          </div>
          <span class="method-arrow">&rarr;</span>
          <div class="method-step">
            <div class="step-label">Step 2</div>
            <div class="step-detail">3 Systems Respond<br><span style="font-size: 11px; color: var(--ali-text-grey);">Ali, GPT-4o, Gemini</span></div>
          </div>
          <span class="method-arrow">&rarr;</span>
          <div class="method-step">
            <div class="step-label">Step 3</div>
            <div class="step-detail">LLM Judge Scores<br><span style="font-size: 11px; color: var(--ali-text-grey);">20 criteria, 1-10 each</span></div>
          </div>
          <span class="method-arrow">&rarr;</span>
          <div class="method-step">
            <div class="step-label">Step 4</div>
            <div class="step-detail">Report Generated<br><span style="font-size: 11px; color: var(--ali-text-grey);">Averages + analysis</span></div>
          </div>
        </div>
      </div>

      <div class="card">
        <h3>The Three Systems</h3>
        <table>
          <tr><th>System</th><th>Model</th><th>Prompt</th><th>What It Tests</th></tr>
          <tr>
            <td><strong style="color: var(--ali-accent);">Ali V3.3.0</strong></td>
            <td>Claude Sonnet</td>
            <td>Full V3.3.0 system prompt (12,288 chars)</td>
            <td>Our product &mdash; problem-based coaching with 10 calibration signals, phase-appropriate guidance, and thread-picking conversation style</td>
          </tr>
          <tr>
            <td><strong style="color: #10B981;">GPT-4o (Sterile)</strong></td>
            <td>OpenAI GPT-4o</td>
            <td>None (raw model, no system prompt)</td>
            <td>What a user gets from a generic AI with zero negotiation coaching</td>
          </tr>
          <tr>
            <td><strong style="color: #3B82F6;">Gemini (Sterile)</strong></td>
            <td>Google Gemini 2.0 Flash</td>
            <td>None (raw model, no system prompt)</td>
            <td>What a user gets from another generic AI with zero negotiation coaching</td>
          </tr>
        </table>
        <p style="margin-top: 16px; font-size: 13px; color: var(--ali-text-grey);"><strong>Why "sterile"?</strong> GPT-4o and Gemini receive NO system prompt &mdash; they respond with their default behavior. This is the baseline: what a user would get by asking ChatGPT or Gemini directly. Ali's advantage should come from our specialized prompt engineering.</p>
      </div>

      <div class="card">
        <h3>The LLM Judge</h3>
        <p>Each response is independently scored by <strong>Claude Sonnet</strong> acting as an automated judge. For each of Tom's 20 criteria, the judge:</p>
        <ul>
          <li>Reads the scenario and the AI's response</li>
          <li>Assigns a score from <strong>1</strong> (poor) to <strong>10</strong> (excellent)</li>
          <li>Provides "What Works," "What Doesn't," and "Improvements" commentary</li>
        </ul>
        <p>The scenario score is the <strong>average of all 20 criterion scores</strong>. The system score is the <strong>average across all 5 scenarios</strong>.</p>
        <p style="font-size: 13px; color: var(--ali-text-grey); margin-top: 8px;"><strong>Important limitation:</strong> LLM judges evaluate single-turn responses only. Ali is designed for multi-turn coaching conversations where value builds over several exchanges. A first-response evaluation inherently favors systems that dump all advice immediately.</p>
      </div>
    </section>

    <!-- What Changed -->
    <section>
      <div class="section-header">
        <div class="section-label">Changelog</div>
        <div class="section-title">What Changed in V3.3.0</div>
      </div>

      <div class="card">
        <div class="change-item">
          <span class="change-tag tag-new">New</span>
          <div><strong>Problem-Based Coaching</strong> &mdash; Ali now identifies problems (relationship, process, goals) instead of labeling deal types. Classification is fully internal.</div>
        </div>
        <div class="change-item">
          <span class="change-tag tag-new">New</span>
          <div><strong>10 Calibration Signals</strong> (was 6) &mdash; Added goals status, relationship quality, process stage, leverage assessment, counterparty behavior, and problem type.</div>
        </div>
        <div class="change-item">
          <span class="change-tag tag-new">New</span>
          <div><strong>Thread-Picking</strong> &mdash; Ali follows ONE thread at a time instead of asking about everything at once. Addresses the "interrogation vs conversation" feedback.</div>
        </div>
        <div class="change-item">
          <span class="change-tag tag-new">New</span>
          <div><strong>Branching Path Options</strong> &mdash; After assessing power, Ali offers 2-3 strategic paths and lets the user choose their approach.</div>
        </div>
        <div class="change-item">
          <span class="change-tag tag-new">New</span>
          <div><strong>Phase-Appropriate Coaching</strong> &mdash; 5 phases (Planning, Preparation, Communication, Deal, Close). Ali won't give planning advice to someone in closing.</div>
        </div>
        <div class="change-item">
          <span class="change-tag tag-new">New</span>
          <div><strong>Calibration Trigger (Exchange 3)</strong> &mdash; If Ali lacks signals by exchange 3, it presents structured calibration questions instead of continuing open-ended questioning.</div>
        </div>
        <div class="change-item">
          <span class="change-tag tag-changed">Changed</span>
          <div><strong>Opening prompt</strong> &mdash; "Hey &mdash; walk me through the deal. What are you trying to get, and what's making it hard?" (was: "what's the real pressure here?")</div>
        </div>
        <div class="change-item">
          <span class="change-tag tag-removed">Removed</span>
          <div><strong>User-facing classification labels</strong> &mdash; Ali no longer says "This is a trading negotiation." Classification informs strategy internally.</div>
        </div>
      </div>
    </section>

    <!-- Evaluation Scores -->
    <section>
      <div class="section-header">
        <div class="section-label">Evaluation Results &mdash; Run 2 (Feb 8)</div>
        <div class="section-title">Ali V3.3.0 vs GPT-4o vs Gemini</div>
      </div>

      <div class="score-grid">
        <div class="score-card winner">
          <div class="system-name">Ali V3.3.0</div>
          <div class="score-value" style="color: var(--ali-accent);">6.5</div>
          <div class="score-unit">/ 10 average</div>
          <div class="score-trend" style="color: var(--ali-text-grey);">Run 1: 6.5 (stable)</div>
        </div>
        <div class="score-card">
          <div class="system-name">GPT-4o (Sterile)</div>
          <div class="score-value" style="color: #10B981;">6.8</div>
          <div class="score-unit">/ 10 average</div>
          <div class="score-trend" style="color: var(--ali-text-grey);">Run 1: 6.7</div>
        </div>
        <div class="score-card">
          <div class="system-name">Gemini (Sterile)</div>
          <div class="score-value" style="color: #3B82F6;">7.3</div>
          <div class="score-unit">/ 10 average</div>
          <div class="score-trend" style="color: var(--ali-warning);">Run 1: 6.3*</div>
        </div>
      </div>

      <div class="insight-box">
        <div class="label">Key Finding</div>
        <p><strong>Ali wins on FEEL, competitors win on DELIVER.</strong> Ali scores best-in-class on cognitive load (+3.6), conversational depth (+1.6), direct business guidance avoidance (+1.6), and empathy (+0.6) &mdash; the conversation <em>experience</em> is superior. But GPT-4o and Gemini deliver actionable guidance 4.6&ndash;4.8 points faster because they dump comprehensive strategies in their first response without asking questions first. The fix: Ali's first response needs a quick tactical insight alongside its follow-up question.</p>
        <p style="margin-top: 12px; font-size: 13px;"><strong>*Gemini Run 1 note:</strong> Gemini scored 2/10 on Scenario 1 in Run 1 due to an API rate limit error, not a real response. Run 2 reflects Gemini's true capability (7.0 on that scenario). The corrected Run 1 average would have been ~6.9.</p>
      </div>
    </section>

    <!-- Full 20-Criterion Comparison -->
    <section>
      <div class="section-header">
        <div class="section-label">Complete Breakdown</div>
        <div class="section-title">All 20 Criteria Scored</div>
      </div>

      <div class="card">
        <h3>General Criteria (1-12)</h3>
        <table class="criterion-full">
          <tr><th>#</th><th>Criterion</th><th style="color: #C4B5FD;">Ali</th><th style="color: #6EE7B7;">GPT</th><th style="color: #93C5FD;">Gemini</th><th>Ali vs Best</th></tr>
          <tr><td>1</td><td>Opening &amp; Rapport</td><td class="score-win">8.0</td><td>6.6</td><td>7.6</td><td class="score-win">+0.4</td></tr>
          <tr><td>2</td><td>Actionable Guidance</td><td class="score-lose">4.4</td><td>8.2</td><td>9.0</td><td class="score-lose">-4.6</td></tr>
          <tr><td>3</td><td>Direct Business Guidance</td><td class="score-win">8.0</td><td>5.8</td><td>6.4</td><td class="score-win">+1.6</td></tr>
          <tr><td>4</td><td>Time to First Value</td><td class="score-lose">4.2</td><td>9.0</td><td>8.4</td><td class="score-lose">-4.8</td></tr>
          <tr><td>5</td><td>Cognitive Load</td><td class="score-win">8.4</td><td>4.8</td><td>3.6</td><td class="score-win">+3.6</td></tr>
          <tr><td>6</td><td>Question Pacing</td><td class="score-win">8.4</td><td>8.0</td><td>6.8</td><td class="score-win">+0.4</td></tr>
          <tr><td>7</td><td>Structure &amp; Clarity</td><td>8.6</td><td class="score-win">9.0</td><td>8.6</td><td style="color: var(--ali-text-grey);">-0.4</td></tr>
          <tr><td>8</td><td>Depth vs. Brevity</td><td class="score-win">7.4</td><td>5.8</td><td>4.6</td><td class="score-win">+1.6</td></tr>
          <tr><td>9</td><td>Framework Transparency</td><td>5.8</td><td>7.0</td><td class="score-win">7.6</td><td class="score-lose">-1.8</td></tr>
          <tr><td>10</td><td>Personalization</td><td class="score-win">8.0</td><td>7.4</td><td>7.8</td><td class="score-win">+0.2</td></tr>
          <tr><td>11</td><td>Tone Calibration</td><td>4.6</td><td>4.6</td><td class="score-win">5.8</td><td class="score-lose">-1.2</td></tr>
          <tr><td>12</td><td>Empathy</td><td class="score-win">6.8</td><td>5.0</td><td>6.2</td><td class="score-win">+0.6</td></tr>
        </table>
      </div>

      <div class="card">
        <h3>Negotiation-Specific Criteria (13-20)</h3>
        <table class="criterion-full">
          <tr><th>#</th><th>Criterion</th><th style="color: #C4B5FD;">Ali</th><th style="color: #6EE7B7;">GPT</th><th style="color: #93C5FD;">Gemini</th><th>Ali vs Best</th></tr>
          <tr><td>13</td><td>Negotiation Relevance</td><td>7.8</td><td>8.2</td><td class="score-win">9.4</td><td class="score-lose">-1.6</td></tr>
          <tr><td>14</td><td>BATNA/ZOPA</td><td class="score-lose">4.6</td><td>5.6</td><td>8.0</td><td class="score-lose">-3.4</td></tr>
          <tr><td>15</td><td>Objection Anticipation</td><td class="score-lose">3.2</td><td>5.2</td><td>7.0</td><td class="score-lose">-3.8</td></tr>
          <tr><td>16</td><td>Bluffing/Deception</td><td>8.0</td><td class="score-win">8.4</td><td>8.2</td><td style="color: var(--ali-text-grey);">-0.4</td></tr>
          <tr><td>17</td><td>Power Imbalance</td><td>6.6</td><td>6.6</td><td class="score-win">7.4</td><td style="color: var(--ali-text-grey);">-0.8</td></tr>
          <tr><td>18</td><td>Ethics &amp; Legality</td><td>8.2</td><td>8.0</td><td class="score-win">8.4</td><td style="color: var(--ali-text-grey);">-0.2</td></tr>
          <tr><td>19</td><td>Confidentiality</td><td class="score-lose">4.6</td><td>5.4</td><td>7.0</td><td class="score-lose">-2.4</td></tr>
          <tr><td>20</td><td>Post-Negotiation</td><td class="score-lose">4.2</td><td>7.8</td><td>8.2</td><td class="score-lose">-4.0</td></tr>
        </table>
      </div>
    </section>

    <!-- Where Ali Wins / Loses (Summary) -->
    <section>
      <div class="section-header">
        <div class="section-label">Strategic Analysis</div>
        <div class="section-title">Strengths &amp; Gaps</div>
      </div>

      <div class="card">
        <h3 style="color: var(--ali-success);">Where Ali V3.3.0 Wins (Conversation Quality)</h3>
        <table>
          <tr><th>Criterion</th><th>Ali</th><th>Best Competitor</th><th>Delta</th></tr>
          <tr><td>Cognitive Load</td><td class="score-win">8.4</td><td>4.8 (GPT)</td><td class="score-win">+3.6</td></tr>
          <tr><td>Direct Business Guidance (avoidance)</td><td class="score-win">8.0</td><td>6.4 (Gemini)</td><td class="score-win">+1.6</td></tr>
          <tr><td>Depth vs. Brevity Balance</td><td class="score-win">7.4</td><td>5.8 (GPT)</td><td class="score-win">+1.6</td></tr>
          <tr><td>Empathy</td><td class="score-win">6.8</td><td>6.2 (Gemini)</td><td class="score-win">+0.6</td></tr>
          <tr><td>Opening &amp; Rapport</td><td class="score-win">8.0</td><td>7.6 (Gemini)</td><td class="score-win">+0.4</td></tr>
          <tr><td>Question Pacing</td><td class="score-win">8.4</td><td>8.0 (GPT)</td><td class="score-win">+0.4</td></tr>
          <tr><td>Personalization</td><td class="score-win">8.0</td><td>7.8 (Gemini)</td><td class="score-win">+0.2</td></tr>
        </table>
        <p style="margin-top: 12px; font-size: 13px; color: var(--ali-text-grey);">Ali's prompt engineering shines in keeping responses digestible, empathetic, and focused. Users process less per message, get better rapport, and receive guidance that stays in the negotiation lane (avoids business advice).</p>
      </div>

      <div class="card">
        <h3 style="color: var(--ali-danger);">Where Ali V3.3.0 Needs Work (Actionable Delivery)</h3>
        <table>
          <tr><th>Criterion</th><th>Ali</th><th>Best Competitor</th><th>Delta</th></tr>
          <tr><td>Time to First Value</td><td class="score-lose">4.2</td><td>9.0 (GPT)</td><td class="score-lose">-4.8</td></tr>
          <tr><td>Actionable Guidance</td><td class="score-lose">4.4</td><td>9.0 (Gemini)</td><td class="score-lose">-4.6</td></tr>
          <tr><td>Post-Negotiation Guidance</td><td class="score-lose">4.2</td><td>8.2 (Gemini)</td><td class="score-lose">-4.0</td></tr>
          <tr><td>Objection Anticipation</td><td class="score-lose">3.2</td><td>7.0 (Gemini)</td><td class="score-lose">-3.8</td></tr>
          <tr><td>BATNA/ZOPA</td><td class="score-lose">4.6</td><td>8.0 (Gemini)</td><td class="score-lose">-3.4</td></tr>
          <tr><td>Confidentiality Coaching</td><td class="score-lose">4.6</td><td>7.0 (Gemini)</td><td class="score-lose">-2.4</td></tr>
        </table>
        <p style="margin-top: 12px; font-size: 13px; color: var(--ali-text-grey);">Ali's coaching approach (asking questions before advising) costs points in single-turn evaluation. The competitors dump comprehensive strategy immediately. The prompt fix: add a brief tactical insight in the first response alongside the diagnostic question. This doesn't mean abandoning the coaching model &mdash; it means delivering a quick win while still engaging in conversation.</p>
      </div>
    </section>

    <!-- Per-Scenario Scores -->
    <section>
      <div class="section-header">
        <div class="section-label">Scenario Results</div>
        <div class="section-title">5 Test Scenarios</div>
      </div>

      <div class="card">
        <table>
          <tr><th>Scenario</th><th>Ali V3.3.0</th><th>GPT-4o</th><th>Gemini</th><th>Winner</th></tr>
          <tr><td>Sole Supplier Lock-In (BATNA)</td><td>6.4</td><td>6.5</td><td class="score-win"><strong>7.0</strong></td><td style="color: #3B82F6; font-weight: 700;">Gemini</td></tr>
          <tr><td>Office Supply Quotes (Bargaining)</td><td class="score-win"><strong>6.9</strong></td><td>6.6</td><td>6.6</td><td class="score-win">Ali</td></tr>
          <tr><td>SaaS Contract Renewal (Trading)</td><td>6.7</td><td>7.2</td><td class="score-win"><strong>7.6</strong></td><td style="color: #3B82F6; font-weight: 700;">Gemini</td></tr>
          <tr><td>Joint Marketing Initiative (Creating)</td><td>5.6</td><td>6.0</td><td class="score-win"><strong>7.4</strong></td><td style="color: #3B82F6; font-weight: 700;">Gemini</td></tr>
          <tr><td>Sarah Chen Salary (Trading)</td><td>6.7</td><td>7.6</td><td class="score-win"><strong>7.8</strong></td><td style="color: #3B82F6; font-weight: 700;">Gemini</td></tr>
        </table>
        <p style="margin-top: 16px; font-size: 13px; color: var(--ali-text-grey);">Ali wins 1/5 scenarios (Office Supply Quotes). Gemini wins 4/5. In single-turn evaluation, Gemini's verbose "dump everything" approach scores well on content completeness, even though it creates significant cognitive overload. Ali's strength &mdash; digestible, conversational coaching &mdash; reveals itself across multiple exchanges, which this eval doesn't capture.</p>
      </div>
    </section>

    <!-- Run History -->
    <section>
      <div class="section-header">
        <div class="section-label">Eval History</div>
        <div class="section-title">Run 1 vs Run 2</div>
      </div>

      <div class="card">
        <h3>Overall Averages Across Runs</h3>
        <table>
          <tr><th>System</th><th>Run 1 (Feb 3)</th><th>Run 2 (Feb 8)</th><th>Change</th></tr>
          <tr><td><strong style="color: var(--ali-accent);">Ali V3.3.0</strong></td><td>6.5</td><td>6.5</td><td class="score-tie">0.0 (stable)</td></tr>
          <tr><td><strong style="color: #10B981;">GPT-4o</strong></td><td>6.7</td><td>6.8</td><td style="color: var(--ali-text-grey);">+0.1</td></tr>
          <tr><td><strong style="color: #3B82F6;">Gemini</strong></td><td>6.3*</td><td>7.3</td><td style="color: var(--ali-warning); font-weight: 600;">+1.0*</td></tr>
        </table>
        <p style="margin-top: 16px; font-size: 13px; color: var(--ali-text-grey);">*Gemini's Run 1 score (6.3) was artificially low due to a rate-limit error on Scenario 1 that scored 2/10. With that correction, Gemini was ~6.9 in Run 1 and 7.3 in Run 2. Ali and GPT-4o scores are stable across runs, indicating <strong>good eval reproducibility</strong>.</p>
      </div>

      <div class="card">
        <h3>Per-Scenario Comparison</h3>
        <table>
          <tr><th>Scenario</th><th>Ali R1&rarr;R2</th><th>GPT R1&rarr;R2</th><th>Gemini R1&rarr;R2</th></tr>
          <tr><td>Sole Supplier Lock-In</td><td>6.4 &rarr; 6.4</td><td>6.0 &rarr; 6.5</td><td>2.0* &rarr; 7.0</td></tr>
          <tr><td>Office Supply Quotes</td><td>7.0 &rarr; 6.9</td><td>7.3 &rarr; 6.6</td><td>7.1 &rarr; 6.6</td></tr>
          <tr><td>SaaS Contract Renewal</td><td>6.6 &rarr; 6.7</td><td>6.9 &rarr; 7.2</td><td>7.4 &rarr; 7.6</td></tr>
          <tr><td>Joint Marketing</td><td>6.0 &rarr; 5.6</td><td>6.1 &rarr; 6.0</td><td>7.2 &rarr; 7.4</td></tr>
          <tr><td>Sarah Chen Salary</td><td>6.7 &rarr; 6.7</td><td>7.4 &rarr; 7.6</td><td>7.6 &rarr; 7.8</td></tr>
        </table>
      </div>
    </section>

    <!-- Tom's 20 Criteria -->
    <section>
      <div class="section-header">
        <div class="section-label">Evaluation Framework</div>
        <div class="section-title">Tom's 20 Scoring Criteria</div>
      </div>

      <div class="card">
        <h3>General (1-12)</h3>
        <table>
          <tr><th>#</th><th>Criterion</th><th>What We're Measuring</th></tr>
          <tr><td>1</td><td><strong>Opening &amp; Rapport</strong></td><td>Comfortable, professional tone without being cold or overly familiar?</td></tr>
          <tr><td>2</td><td><strong>Actionable Guidance</strong></td><td>Concrete, usable advice (not just generic principles)?</td></tr>
          <tr><td>3</td><td><strong>Direct Business Guidance</strong></td><td>Avoids business advice; gives negotiation communication/planning instead?</td></tr>
          <tr><td>4</td><td><strong>Time to First Value</strong></td><td>How many exchanges before the user gets something useful?</td></tr>
          <tr><td>5</td><td><strong>Cognitive Load</strong></td><td>How much does the user have to process per response?</td></tr>
          <tr><td>6</td><td><strong>Question Pacing</strong></td><td>Gathers info at natural pace, or overwhelms with questions?</td></tr>
          <tr><td>7</td><td><strong>Structure &amp; Clarity</strong></td><td>Response is easy to follow and digest?</td></tr>
          <tr><td>8</td><td><strong>Depth vs. Brevity</strong></td><td>Enough substance without being overwhelming?</td></tr>
          <tr><td>9</td><td><strong>Framework Transparency</strong></td><td>Explains the WHY of an approach, not just the HOW?</td></tr>
          <tr><td>10</td><td><strong>Personalization</strong></td><td>Tailored to the user's specific situation?</td></tr>
          <tr><td>11</td><td><strong>Tone Calibration</strong></td><td>Offers options (firm, collaborative, soft) or one-size-fits-all?</td></tr>
          <tr><td>12</td><td><strong>Empathy</strong></td><td>Acknowledges emotional/psychological aspects?</td></tr>
        </table>
      </div>

      <div class="card">
        <h3>Negotiation-Specific (13-20)</h3>
        <table>
          <tr><th>#</th><th>Criterion</th><th>What We're Measuring</th></tr>
          <tr><td>13</td><td><strong>Relevance</strong></td><td>Questions/responses directly useful for the negotiation context?</td></tr>
          <tr><td>14</td><td><strong>BATNA/ZOPA</strong></td><td>Helps users understand alternatives and zone of agreement?</td></tr>
          <tr><td>15</td><td><strong>Objection Anticipation</strong></td><td>Prepares the user for likely counterarguments?</td></tr>
          <tr><td>16</td><td><strong>Bluffing/Deception</strong></td><td>Encourages honesty or coaches manipulation?</td></tr>
          <tr><td>17</td><td><strong>Power Imbalance</strong></td><td>Acknowledges weak leverage and adjusts accordingly?</td></tr>
          <tr><td>18</td><td><strong>Ethics &amp; Legality</strong></td><td>Calls out illegal or unethical actions?</td></tr>
          <tr><td>19</td><td><strong>Confidentiality</strong></td><td>Advises on what to disclose vs. withhold?</td></tr>
          <tr><td>20</td><td><strong>Post-Negotiation</strong></td><td>Advises on confirming terms in writing, next steps?</td></tr>
        </table>
      </div>

      <div class="insight-box">
        <div class="label">Testing Protocol</div>
        <p><strong>Apples-to-apples comparison:</strong> Same 5 scenarios, same prompt, across Ali (Claude Sonnet + V3.3.0), GPT-4o (sterile), and Gemini (sterile). Each response scored on all 20 criteria by Claude Sonnet as LLM judge. Rate 1-10 per criterion. This eval runs automatically &mdash; execute <code>npx tsx scripts/eval-ali-prompt.ts</code> after any prompt change. Results are saved to <code>docs/eval-reports/</code> with timestamped filenames.</p>
      </div>
    </section>

    <!-- Braintrust Setup -->
    <section>
      <div class="section-header">
        <div class="section-label">Getting Started</div>
        <div class="section-title">Braintrust Playground Access</div>
      </div>

      <div class="card">
        <h3>What is Braintrust?</h3>
        <p>Braintrust is the platform where you can <strong>edit Ali's system prompt, test it with different scenarios, and compare models side-by-side</strong> &mdash; all in a visual playground. No code required.</p>
        <p>When you're happy with changes, message Terrance "Ready to sync" and the updated prompt gets pulled into the codebase and deployed.</p>
      </div>

      <div class="card">
        <h3>Setup Steps</h3>
        <div class="step">
          <div class="step-num">1</div>
          <div class="step-content">
            <h4>Accept Invite</h4>
            <p>You'll receive an email invitation to join the <strong>aligned-negotiation</strong> project on <a href="https://braintrust.dev" style="color: var(--ali-accent);">braintrust.dev</a>. Click "Accept" and create an account.</p>
          </div>
        </div>
        <div class="step">
          <div class="step-num">2</div>
          <div class="step-content">
            <h4>Open the Playground</h4>
            <p>Navigate to <strong>Prompts</strong> in the left sidebar, then click <strong>ali-v3-conversational</strong>. This is Ali's brain &mdash; V3.3.0 is live.</p>
          </div>
        </div>
        <div class="step">
          <div class="step-num">3</div>
          <div class="step-content">
            <h4>Test Scenarios</h4>
            <p>Type a negotiation scenario in the chat area and click <strong>Run</strong> (or Cmd+Enter). Try the 5 test scenarios from this doc.</p>
          </div>
        </div>
        <div class="step">
          <div class="step-num">4</div>
          <div class="step-content">
            <h4>Edit &amp; Iterate</h4>
            <p>Modify the prompt text, run again, compare. Braintrust keeps version history so you can always roll back.</p>
          </div>
        </div>
        <div class="step">
          <div class="step-num">5</div>
          <div class="step-content">
            <h4>Signal Ready</h4>
            <p>When satisfied, message Terrance: <em>"Prompt updated in staging &mdash; ready to sync."</em></p>
          </div>
        </div>
      </div>

      <div class="card">
        <h3>What You Can Safely Change</h3>
        <ul>
          <li><strong>Tone &amp; voice</strong> &mdash; Opening lines, follow-up phrasing, formality level</li>
          <li><strong>Opening question</strong> &mdash; What Ali says first to set the tone</li>
          <li><strong>Path option language</strong> &mdash; How Ali frames strategic choices</li>
          <li><strong>Phase coaching content</strong> &mdash; Advice for each negotiation phase</li>
          <li><strong>Guardrail language</strong> &mdash; How Ali redirects off-topic questions</li>
        </ul>
        <p style="margin-top: 12px; font-size: 13px; color: var(--ali-text-grey);"><strong>Modify with care:</strong> Signal extraction rules, inference rules, calibration thresholds. <strong>Don't touch:</strong> Classification decision flow, confidence calculation (notify Terrance for these).</p>
      </div>
    </section>

    <!-- Test Scenarios -->
    <section>
      <div class="section-header">
        <div class="section-label">Reference</div>
        <div class="section-title">Standard Test Scenarios</div>
      </div>

      <div class="card">
        <h3>1. Sole Supplier Lock-In (BATNA Deficiency)</h3>
        <p><em>"Our sole supplier for a critical component just told us they're raising prices 40%. Contract renews in 30 days. No alternatives exist in this market."</em></p>
      </div>
      <div class="card">
        <h3>2. Office Supply Quotes (Bargaining)</h3>
        <p><em>"Getting quotes from 5 different office furniture vendors. Just need the best price on standard desks and chairs."</em></p>
      </div>
      <div class="card">
        <h3>3. SaaS Contract Renewal (Trading)</h3>
        <p><em>"I'm negotiating a software contract renewal. 2 years with this vendor, good relationship, but they raised prices 30%. 3 other vendors possible. Negotiating price, SLAs, payment terms, volume, implementation."</em></p>
      </div>
      <div class="card">
        <h3>4. Joint Marketing Initiative (Creating)</h3>
        <p><em>"5-year vendor relationship. Discussing a joint marketing initiative. Great trust, collaborative relationship."</em></p>
      </div>
      <div class="card">
        <h3>5. Sarah Chen Salary Negotiation (Trading)</h3>
        <p><em>"3 years as a senior engineer. Competing offer for 25% more. Like my current team but feel underpaid. Annual review next month."</em></p>
      </div>
    </section>

    <!-- Next Steps -->
    <section>
      <div class="section-header">
        <div class="section-label">Action Items</div>
        <div class="section-title">What Happens Next</div>
      </div>

      <div class="card">
        <table>
          <tr><th>Action</th><th>Owner</th><th>Status</th></tr>
          <tr><td>V3.3.0 deployed to production</td><td>Terrance</td><td style="color: var(--ali-success); font-weight: 600;">Done</td></tr>
          <tr><td>Run 2 evaluation completed</td><td>Terrance</td><td style="color: var(--ali-success); font-weight: 600;">Done (Feb 8)</td></tr>
          <tr><td>Gemini added to eval comparison</td><td>Terrance</td><td style="color: var(--ali-success); font-weight: 600;">Done</td></tr>
          <tr><td>Braintrust invites to Tom, Scott, Chelsea</td><td>Terrance</td><td style="color: var(--ali-danger); font-weight: 600;">Blocked</td></tr>
          <tr><td>Review prompt in Braintrust playground</td><td>Tom, Mark, Scott</td><td>Pending invite</td></tr>
          <tr><td>Address "Time to First Value" gap</td><td>Tom + Terrance</td><td style="color: var(--ali-warning); font-weight: 600;">Discussion needed</td></tr>
          <tr><td>Advisory system prompt draft</td><td>Tom</td><td>In progress</td></tr>
          <tr><td>6 coaching call recordings</td><td>Lee / Moose / Caleb</td><td>Pending</td></tr>
          <tr><td>10-question calibration beta</td><td>Tom</td><td>In progress</td></tr>
          <tr><td>Weekly Monday check-ins</td><td>All</td><td>Active</td></tr>
        </table>
      </div>

      <div style="text-align: center; margin-top: 32px;">
        <a href="https://braintrust.dev" class="action-btn">Open Braintrust Playground</a>
        <p style="margin-top: 12px; font-size: 12px; color: var(--ali-text-grey);">Contact Terrance for your Braintrust invite.</p>
      </div>
    </section>

    <!-- Footer -->
    <div style="text-align: center; padding: 32px 0; font-size: 12px; color: var(--ali-text-grey);">
      <p>Ali MVP &mdash; Aligned Negotiation &mdash; Confidential</p>
      <p>Updated: February 8, 2026 | Eval Script: <code>scripts/eval-ali-prompt.ts</code> | Run 2 of 2</p>
    </div>
  </div>
</body>
</html>
